{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff91b69f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:37:00.250105Z",
     "iopub.status.busy": "2025-09-10T10:37:00.249890Z",
     "iopub.status.idle": "2025-09-10T10:38:43.710884Z",
     "shell.execute_reply": "2025-09-10T10:38:43.709713Z"
    },
    "papermill": {
     "duration": 103.467743,
     "end_time": "2025-09-10T10:38:43.713153",
     "exception": false,
     "start_time": "2025-09-10T10:37:00.245410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\r\n",
      "Collecting torch-scatter\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\r\n",
      "Successfully installed torch-scatter-2.1.2+pt26cu124\r\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\r\n",
      "Collecting torch-sparse\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\r\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\r\n",
      "Installing collected packages: torch-sparse\r\n",
      "Successfully installed torch-sparse-0.6.18+pt26cu124\r\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\r\n",
      "Collecting torch-cluster\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.3)\r\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-cluster) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-cluster) (2024.2.0)\r\n",
      "Installing collected packages: torch-cluster\r\n",
      "Successfully installed torch-cluster-1.6.3+pt26cu124\r\n",
      "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\r\n",
      "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-ao3e8vld\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-ao3e8vld\r\n",
      "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 5ab08331850d0e3c232c99d11ed86778cf2c9445\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.12.13)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2025.5.1)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (7.0.0)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.5.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.20.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric==2.7.0) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric==2.7.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric==2.7.0) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric==2.7.0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric==2.7.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric==2.7.0) (2024.2.0)\r\n",
      "Building wheels for collected packages: torch-geometric\r\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1273763 sha256=afbd9f1ae4e96d6289d9fd7b5c8c85f7bded25987ac2408a198080027369d2b6\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9o4n16en/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\r\n",
      "Successfully built torch-geometric\r\n",
      "Installing collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.7.0\r\n",
      "Collecting torch-geometric-temporal\r\n",
      "  Downloading torch_geometric_temporal-0.56.2-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (4.4.2)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (3.0.12)\r\n",
      "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (0.6.18+pt26cu124)\r\n",
      "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (2.1.2+pt26cu124)\r\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (2.7.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (1.26.4)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal) (3.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric-temporal) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (4.14.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-geometric-temporal)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-geometric-temporal) (1.3.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (3.12.13)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (7.0.0)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch-geometric-temporal) (3.5.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse->torch-geometric-temporal) (1.15.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.20.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-geometric-temporal) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric-temporal) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric-temporal) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric-temporal) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric-temporal) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch-geometric-temporal) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric-temporal) (2024.2.0)\r\n",
      "Downloading torch_geometric_temporal-0.56.2-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-geometric-temporal\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-geometric-temporal-0.56.2\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a8c06",
   "metadata": {
    "papermill": {
     "duration": 0.03983,
     "end_time": "2025-09-10T10:38:43.798437",
     "exception": false,
     "start_time": "2025-09-10T10:38:43.758607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Customized Dataset for SpatioTemporalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be256758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:43.880946Z",
     "iopub.status.busy": "2025-09-10T10:38:43.880341Z",
     "iopub.status.idle": "2025-09-10T10:38:55.262873Z",
     "shell.execute_reply": "2025-09-10T10:38:55.262168Z"
    },
    "papermill": {
     "duration": 11.430208,
     "end_time": "2025-09-10T10:38:55.264269",
     "exception": false,
     "start_time": "2025-09-10T10:38:43.834061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data \n",
    "class SpatioTemporalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A customized torch geometric dataset for spatiotemporal data,\n",
    "    using the sliding window technique\n",
    "    \n",
    "    Args:\n",
    "        data_array(np.ndarray): 3D data in form (nodes, features, timestamps)\n",
    "        edge_index (np.ndarray): 2D np.array consists of edges in graph in form of (source, destination)\n",
    "        edge_weight (np.ndarray): weight matrix with correspond to edges\n",
    "        lookback (int): the length of past window used to predict the next days\n",
    "        horizon (int): number of next days needs to be predcted\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_array, edge_index, edge_attr=None, edge_weight=None, transform=None, lookback=90, horizon=30):\n",
    "        super().__init__()\n",
    "        self.lookback = lookback\n",
    "        self.horizon = horizon\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.x_data = torch.from_numpy(data_array).float()\n",
    "        self.edge_index = torch.from_numpy(edge_index).long()\n",
    "        \n",
    "        \n",
    "        self.edge_weight = None \n",
    "        self.edge_attr = None\n",
    "        \n",
    "        if (edge_attr is not None):\n",
    "            self.edge_attr = torch.from_numpy(edge_attr).float()\n",
    "        if (edge_weight is not None):\n",
    "            self.edge_weight = torch.from_numpy(edge_weight).float()\n",
    "        \n",
    "        self._num_timestamps = data_array.shape[2]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of available dataset depending on the length of lookback \n",
    "        and future horizon\n",
    "        \"\"\"\n",
    "        return self._num_timestamps - self.lookback - self.horizon + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_x = idx \n",
    "        end_x = start_x + self.lookback\n",
    "        \n",
    "        start_y = end_x\n",
    "        end_y = start_y + self.horizon\n",
    "        \n",
    "        x_window = self.x_data[:, :, start_x:end_x]\n",
    "        y_window = self.x_data[:, :, start_y:end_y]  \n",
    "        \n",
    "        data = Data(\n",
    "            x = x_window,\n",
    "            edge_index = self.edge_index,\n",
    "            edge_attr = self.edge_attr,\n",
    "            edge_weight=self.edge_weight, \n",
    "            y=y_window\n",
    "        )   \n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfc3ec",
   "metadata": {
    "papermill": {
     "duration": 0.026196,
     "end_time": "2025-09-10T10:38:55.318603",
     "exception": false,
     "start_time": "2025-09-10T10:38:55.292407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data to customized Data and split into K-folds using Time-series K-folds for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d267dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:55.373482Z",
     "iopub.status.busy": "2025-09-10T10:38:55.373022Z",
     "iopub.status.idle": "2025-09-10T10:38:55.376620Z",
     "shell.execute_reply": "2025-09-10T10:38:55.375979Z"
    },
    "papermill": {
     "duration": 0.032235,
     "end_time": "2025-09-10T10:38:55.377763",
     "exception": false,
     "start_time": "2025-09-10T10:38:55.345528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "LOOKBACK = 90\n",
    "HORIZON = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e075ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:55.432637Z",
     "iopub.status.busy": "2025-09-10T10:38:55.432413Z",
     "iopub.status.idle": "2025-09-10T10:38:56.144732Z",
     "shell.execute_reply": "2025-09-10T10:38:56.144061Z"
    },
    "papermill": {
     "duration": 0.741098,
     "end_time": "2025-09-10T10:38:56.146173",
     "exception": false,
     "start_time": "2025-09-10T10:38:55.405075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from torch_geometric.transforms import GCNNorm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def convert3dtensor(nodes, df: pd.DataFrame):\n",
    "    \"\"\" \n",
    "    Convert 2D sp500 dataframe into 3D shape tensor \n",
    "    which is in form (n_nodes, n_timestamps, n_features)\n",
    "    \n",
    "    Args:\n",
    "\n",
    "        - df (pd.DataFrame): Dataframe needed to be converted\n",
    "        - nodes (np.ndarray): A np.ndarry consists of stock labels\n",
    "    Return:\n",
    "        (np.ndarray): Data returned in 3D shape\n",
    "    \"\"\"\n",
    "    df.set_index(['Symbol', 'Date'], inplace=True)\n",
    "    \n",
    "    return np.stack(\n",
    "        [df.loc[node].values.T for node in nodes],\n",
    "        axis=0\n",
    "    ).transpose(0, 2, 1)\n",
    "\n",
    "\n",
    "def load_data(train=True):\n",
    "    \n",
    "    \"\"\" \n",
    "    A funtion aims to split inital data into train, test, split using Time-series K-fold split technique.\n",
    "    \n",
    "    The last month data is considered as the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        - train (bool): If True, return 4 folds, each fold consists of both training & validation sets. \n",
    "        Otherwise, it would return test set with entire training set.\n",
    "    Return:\n",
    "        (list): Set of couples, each couple consists of 2 sets, the second following the first by time\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('/kaggle/input/s-and-p500-stock-market/clear_sp500.csv').drop(columns=['Dividends', 'Stock Splits'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    nodes = df['Symbol'].unique()\n",
    "    \n",
    "    timelines = [\n",
    "        pd.Timestamp(year=2025, month=4, day=1, tz='UTC'),\n",
    "        pd.Timestamp(year=2025, month=5, day=1, tz='UTC'),\n",
    "        pd.Timestamp(year=2025, month=6, day=1, tz='UTC'),\n",
    "        pd.Timestamp(year=2025, month=7, day=1, tz='UTC'),\n",
    "        pd.Timestamp(year=2025, month=8, day=1, tz='UTC')\n",
    "    ]\n",
    "    \n",
    "    predicted_range = pd.Timedelta(days=30)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    feature_columns = df.columns.tolist()\n",
    "    feature_columns.remove('Symbol')\n",
    "    feature_columns.remove('Date')\n",
    "    \n",
    "    df[feature_columns] = np.log1p(df[feature_columns])\n",
    "    feature_columns.remove('Adj Close')\n",
    "    \n",
    "    if train:\n",
    "        \n",
    "        for i in range(4):\n",
    "            train_df = df[df['Date'] < timelines[i]].copy().reset_index(drop=True)\n",
    "            valid_df = df[(df['Date'] >= (timelines[i] - pd.Timedelta(days=2*LOOKBACK))) & (df['Date'] <= \n",
    "                        \n",
    "                        timelines[i] + predicted_range)].copy().reset_index(drop=True)\n",
    "            \n",
    "            # scaler = StandardScaler().fit(train_df[feature_columns])\n",
    "            # train_df[feature_columns] = scaler.transform(train_df[feature_columns])\n",
    "            # valid_df[feature_columns] = scaler.transform(valid_df[feature_columns])\n",
    "            \n",
    "            folds.append((convert3dtensor(nodes, train_df), \n",
    "                          convert3dtensor(nodes, valid_df)))\n",
    "    \n",
    "    else:\n",
    "        train_df = df[df['Date'] < timelines[4]].copy().reset_index(drop=True)\n",
    "        \n",
    "        test_df = df[df['Date'] >= (timelines[4] - pd.Timedelta(days=3*LOOKBACK))].copy().reset_index(drop=True)\n",
    "        \n",
    "        scaler = StandardScaler().fit(train_df[feature_columns])\n",
    "        # train_df[feature_columns] = scaler.transform(train_df[feature_columns])\n",
    "        # test_df[feature_columns] = scaler.transform(test_df[feature_columns])\n",
    "        \n",
    "        folds.append((convert3dtensor(nodes, train_df),\n",
    "                     convert3dtensor(nodes, test_df)))\n",
    "        \n",
    "    return folds\n",
    "        \n",
    "def load_edge(adj_path=\"/kaggle/input/adjacencymatricies/adj_correlation.npy\"):\n",
    "    \"\"\" \n",
    "    A function aims to construct edge-related matrix using the \n",
    "    pre-defined adjacency matrix\n",
    "    \n",
    "    Args:\n",
    "        adj_path (str): Path to the corresponding adjacency matrix, which is \n",
    "        either correlation adjacency matrix or AE combined BERT adjacency matrix\n",
    "        \n",
    "    Return:\n",
    "        (np.ndarray, np.ndarray): 2 edge-related matricies, the first one\n",
    "        is edge_index matrix, which is in form of (2, num of edges), each row representing for\n",
    "        (source, destination), and the other is edge_weight matrix in form of (edge_weight,) each row\n",
    "        representing for weight of the corresponding edge\n",
    "    \"\"\"\n",
    "    adj_matrix = np.load(adj_path)\n",
    "    \n",
    "    nodes_nb = len(adj_matrix)\n",
    "    edge_nb = np.count_nonzero(adj_matrix)\n",
    "    edge_index = np.zeros((2, edge_nb))\n",
    "    edge_weight = np.zeros((edge_nb))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(nodes_nb):\n",
    "        for j in range(nodes_nb):\n",
    "            if (weight := adj_matrix[i, j]) != 0:\n",
    "                edge_index[0, count], edge_index[1, count] = i, j\n",
    "                edge_weight[count] = weight\n",
    "                count += 1\n",
    "                \n",
    "    return edge_index, edge_weight\n",
    "\n",
    "def load_torchgeometric_data(train=True, LOOKBACK = 90, HORIZON=30, adj_path=\"/kaggle/input/adjacencymatricies/adj_correlation.npy\"):\n",
    "    \"\"\"\n",
    "    A funtion aims to split inital data into train, test, split using Time-series K-fold split technique.\n",
    "    The data must be in form of customized SpatioTemporalDataset\n",
    "    \n",
    "    The last month data is considered as the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        - train (bool): If True, return 4 folds, each fold consists of both training & validation sets. \n",
    "        Otherwise, it would return test set with entire training set.\n",
    "        - adj_path (str): Path to corresponding adjacency matrix\n",
    "        - LOOKBACK (int): the length of past window used to predict the next days\n",
    "        - HORIZON (int): number of next days needs to be predicted\n",
    "    Return:\n",
    "        (list): Set of couples, each couple consists of 2 sets, the second following the first by time\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_index, edge_weight = load_edge(adj_path)\n",
    "    \n",
    "    folds = load_data(train)\n",
    "    \n",
    "    new_folds = []\n",
    "    \n",
    "    transfrom = GCNNorm()\n",
    "    \n",
    "    for fold in folds:\n",
    "        train, other = fold[0], fold[1]\n",
    "        \n",
    "        converted_train = train.transpose(0, 2, 1)\n",
    "        converted_other = other.transpose(0, 2, 1)\n",
    "        \n",
    "        train_datset = SpatioTemporalDataset(\n",
    "            data_array=converted_train,\n",
    "            edge_index=edge_index,\n",
    "            edge_weight=edge_weight,\n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON,\n",
    "            transform=transfrom\n",
    "        )\n",
    "        \n",
    "        test_dataset = SpatioTemporalDataset(\n",
    "            data_array=converted_other,\n",
    "            edge_index=edge_index,\n",
    "            edge_weight=edge_weight,\n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON,\n",
    "            transform=transfrom\n",
    "        )\n",
    "        \n",
    "        new_folds.append((train_datset, test_dataset))\n",
    "        \n",
    "    return new_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a5959",
   "metadata": {
    "papermill": {
     "duration": 0.025978,
     "end_time": "2025-09-10T10:38:56.244567",
     "exception": false,
     "start_time": "2025-09-10T10:38:56.218589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training & Evalutation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28647d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:56.301124Z",
     "iopub.status.busy": "2025-09-10T10:38:56.300278Z",
     "iopub.status.idle": "2025-09-10T10:38:56.304280Z",
     "shell.execute_reply": "2025-09-10T10:38:56.303714Z"
    },
    "papermill": {
     "duration": 0.033747,
     "end_time": "2025-09-10T10:38:56.305417",
     "exception": false,
     "start_time": "2025-09-10T10:38:56.271670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "HORIZON = 30\n",
    "TARGET_IDX = 4\n",
    "ADJ_PATH = '/kaggle/input/adjacencymatricies/adj_correlation.npy'\n",
    "ADJ_TYPE = \"CORRELATION\"\n",
    "\n",
    "# Model hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5170a2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:56.359306Z",
     "iopub.status.busy": "2025-09-10T10:38:56.359098Z",
     "iopub.status.idle": "2025-09-10T10:38:56.380297Z",
     "shell.execute_reply": "2025-09-10T10:38:56.379776Z"
    },
    "papermill": {
     "duration": 0.049309,
     "end_time": "2025-09-10T10:38:56.381371",
     "exception": false,
     "start_time": "2025-09-10T10:38:56.332062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, GATv2Conv \n",
    "from torch_geometric.loader import DataLoader   \n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN, A3TGCN2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_size):\n",
    "        super().__init__()\n",
    "        self.tgnn = A3TGCN(\n",
    "            in_channels = in_channels,\n",
    "            out_channels = hidden_size,\n",
    "            periods = LOOKBACK,\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, HORIZON)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # X: [batchsize * num_nodes, num_features, lookback]\n",
    "        last_known_value = x[:, TARGET_IDX, -1].unsqueeze(1)\n",
    "        h = self.tgnn(x, edge_index, edge_weight)\n",
    "\n",
    "        delta = self.linear(self.relu(h))\n",
    "        \n",
    "        output = last_known_value + delta\n",
    "        # h = F.relu(h)\n",
    "        # h = self.linear(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18848089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:38:56.435878Z",
     "iopub.status.busy": "2025-09-10T10:38:56.435389Z",
     "iopub.status.idle": "2025-09-10T10:39:13.685773Z",
     "shell.execute_reply": "2025-09-10T10:39:13.684932Z"
    },
    "papermill": {
     "duration": 17.279612,
     "end_time": "2025-09-10T10:39:13.687543",
     "exception": false,
     "start_time": "2025-09-10T10:38:56.407931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folds = load_torchgeometric_data(\n",
    "    train=True,\n",
    "    LOOKBACK=LOOKBACK,\n",
    "    HORIZON=HORIZON,\n",
    "    adj_path=ADJ_PATH\n",
    ")\n",
    "\n",
    "test_folds = load_torchgeometric_data(\n",
    "    train=False,\n",
    "    LOOKBACK=LOOKBACK,\n",
    "    HORIZON=HORIZON, \n",
    "    adj_path=ADJ_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88861d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:39:13.746237Z",
     "iopub.status.busy": "2025-09-10T10:39:13.745982Z",
     "iopub.status.idle": "2025-09-10T10:39:13.779898Z",
     "shell.execute_reply": "2025-09-10T10:39:13.779381Z"
    },
    "papermill": {
     "duration": 0.06234,
     "end_time": "2025-09-10T10:39:13.780971",
     "exception": false,
     "start_time": "2025-09-10T10:39:13.718631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_channels = train_folds[0][0][0].x.shape[-2]\n",
    "hidden_size = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6921ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:39:13.834167Z",
     "iopub.status.busy": "2025-09-10T10:39:13.833954Z",
     "iopub.status.idle": "2025-09-10T10:39:13.838278Z",
     "shell.execute_reply": "2025-09-10T10:39:13.837470Z"
    },
    "papermill": {
     "duration": 0.03185,
     "end_time": "2025-09-10T10:39:13.839446",
     "exception": false,
     "start_time": "2025-09-10T10:39:13.807596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_folds_train_losses = []\n",
    "# all_folds_valid_losses = []\n",
    "\n",
    "# for fold_idx, (trainset, validset) in enumerate(train_folds):\n",
    "#     print(f\"=============== FOLD {fold_idx + 1}/{len(train_folds)} ================\")\n",
    "    \n",
    "#     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     validloader = DataLoader(validset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "#     model = TemporalGNN(\n",
    "#         in_channels=in_channels,\n",
    "#         hidden_sie=hidden_size,\n",
    "#         out_channels=out_channels\n",
    "#     ).to(device)\n",
    "    \n",
    "#     criterion = nn.L1Loss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         model.train()\n",
    "#         train_loop = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
    "#         for data in train_loop:\n",
    "#             data = data.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             out = model(data.x, data.edge_index, data.edge_weight)\n",
    "#             target = data.y[:, TARGET_IDX]\n",
    "#             loss = criterion(out, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loop.set_postfix(loss=loss.item())\n",
    "#     torch.save(model, f'/kaggle/working/A3TGCN_{ADJ_TYPE}_FOLD{fold_idx}.pt')    \n",
    "#     final_train_loss = 0\n",
    "#     final_valid_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in trainloader:\n",
    "#             data = data.to(device)\n",
    "#             out = model(data.x, data.edge_index, data.edge_weight)\n",
    "#             target = data.y[:, TARGET_IDX, :]\n",
    "#             final_train_loss += criterion(out, target).item()\n",
    "        \n",
    "#         for data in validloader:\n",
    "#             data = data.to(device)\n",
    "#             out = model(data.x, data.edge_index, data.edge_weight)\n",
    "#             target = data.y[:, TARGET_IDX]\n",
    "#             final_valid_loss += criterion(out, target).item()\n",
    "            \n",
    "#     avg_train_loss = final_train_loss / len(trainloader)\n",
    "#     avg_valid_loss = final_valid_loss / len(validloader)\n",
    "    \n",
    "#     all_folds_train_losses.append(avg_train_loss)\n",
    "#     all_folds_valid_losses.append(avg_valid_loss)\n",
    "#     print(f\"Fold {fold_idx + 1} - Final Train Loss: {avg_train_loss:.6f}, Final Valid Loss: {avg_valid_loss:.6f}\\n\")\n",
    "\n",
    "\n",
    "# print(\"=============== K-FOLD SUMMARY ===============\")\n",
    "# print(f\"Average Train Loss across {len(train_folds)} folds: {np.mean(all_folds_train_losses):.6f}\")\n",
    "# print(f\"Average Valid Loss across {len(train_folds)} folds: {np.mean(all_folds_valid_losses):.6f}\")\n",
    "# print(\"============================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6810153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:39:13.893081Z",
     "iopub.status.busy": "2025-09-10T10:39:13.892853Z",
     "iopub.status.idle": "2025-09-10T11:35:59.551993Z",
     "shell.execute_reply": "2025-09-10T11:35:59.551244Z"
    },
    "papermill": {
     "duration": 3405.687891,
     "end_time": "2025-09-10T11:35:59.553436",
     "exception": false,
     "start_time": "2025-09-10T10:39:13.865545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing model for final training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 1/10: 100%|██████████| 112/112 [05:36<00:00,  3.00s/it, loss=0.0414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10Train: 0.07173089134240788Test: 0.05181296914815903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 2/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10Train: 0.047202829138508866Test: 0.05182524025440216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 3/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10Train: 0.046983077856046815Test: 0.05172349885106087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 4/10: 100%|██████████| 112/112 [05:41<00:00,  3.05s/it, loss=0.0458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10Train: 0.04698057901779456Test: 0.0515814833343029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 5/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10Train: 0.046959495437996726Test: 0.051845673471689224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 6/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10Train: 0.04696370637975633Test: 0.05127706751227379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 7/10: 100%|██████████| 112/112 [05:41<00:00,  3.05s/it, loss=0.0693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10Train: 0.04711957332412047Test: 0.05125008895993233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 8/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10Train: 0.04692251042329839Test: 0.051407791674137115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 9/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10Train: 0.046908849085282Test: 0.05127124860882759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Epoch 10/10: 100%|██████████| 112/112 [05:40<00:00,  3.04s/it, loss=0.0431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10Train: 0.046928094999332516Test: 0.05126102641224861\n"
     ]
    }
   ],
   "source": [
    "final_trainset, testset = test_folds[0]\n",
    "final_trainloader = DataLoader(final_trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader([testset[len(testset) - 1]], batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Re-initializing model for final training...\")\n",
    "final_model = TemporalGNN(\n",
    "    in_channels=in_channels,\n",
    "    hidden_size=hidden_size,\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.L1Loss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    final_model.train()\n",
    "    train_loop = tqdm(final_trainloader, desc=f\"Final Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    total_train_loss = 0\n",
    "    for data in train_loop:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = final_model(data.x, data.edge_index, data.edge_weight)\n",
    "        target = data.y[:, TARGET_IDX, :]\n",
    "        # print(out.shape, target.shape)\n",
    "        loss = criterion(out, target)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    total_train_loss /= len(final_trainloader)\n",
    "    final_model.eval()\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            data = data.to(device)\n",
    "            out = final_model(data.x, data.edge_index, data.edge_weight)\n",
    "            target = data.y[:, TARGET_IDX, :]\n",
    "            loss = criterion(out, target)\n",
    "            total_test_loss += loss.item()\n",
    "        total_test_loss /= len(testloader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\"\n",
    "          f\"Train: {total_train_loss}\"\n",
    "          f\"Test: {total_test_loss}\")\n",
    "\n",
    "torch.save(final_model, f'/kaggle/working/A3TGCN_{ADJ_TYPE}_FINAL_MODEL.pt')\n",
    "# print(\"\\nFinal model saved to /kaggle/working/A3TGCN_AE-BERT_FINAL_MODEL\")\n",
    "\n",
    "# 4. Đánh giá cuối cùng trên tập test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2949c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:35:59.801378Z",
     "iopub.status.busy": "2025-09-10T11:35:59.800691Z",
     "iopub.status.idle": "2025-09-10T11:36:00.194290Z",
     "shell.execute_reply": "2025-09-10T11:36:00.193553Z"
    },
    "papermill": {
     "duration": 0.519088,
     "end_time": "2025-09-10T11:36:00.195526",
     "exception": false,
     "start_time": "2025-09-10T11:35:59.676438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "  PERFORMANCE ON LAST TEST SAMPLE (ORIGINAL SCALE) \n",
      "===========================================\n",
      "-> MAE (Mean Absolute Error):      11.692847\n",
      "-> MSE (Mean Squared Error):       898.463029\n",
      "-> RMSE (Root Mean Squared Error): 29.974373\n",
      "-> R² Score:                       0.996843\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        data = data.to(device)\n",
    "        out = final_model(data.x, data.edge_index, data.edge_weight)\n",
    "        target = data.y[:, TARGET_IDX, :]\n",
    "        restored_output = np.expm1(out.cpu().numpy().flatten())\n",
    "        restored_target = np.expm1(target.cpu().numpy().flatten())\n",
    "\n",
    "r2 = r2_score(restored_target, restored_output)\n",
    "mae = mean_absolute_error(restored_target, restored_output)\n",
    "rmse = np.sqrt(mean_squared_error(restored_target, restored_output))\n",
    "\n",
    "print(f\"\\n===========================================\")\n",
    "print(f\"  PERFORMANCE ON LAST TEST SAMPLE (ORIGINAL SCALE) \")\n",
    "print(f\"===========================================\")\n",
    "print(f\"-> MAE (Mean Absolute Error):      {mae:.6f}\")\n",
    "print(f\"-> MSE (Mean Squared Error):       {rmse ** 2:.6f}\")\n",
    "print(f\"-> RMSE (Root Mean Squared Error): {rmse:.6f}\")\n",
    "print(f\"-> R² Score:                       {r2:.6f}\")\n",
    "print(f\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f776784",
   "metadata": {
    "papermill": {
     "duration": 0.116454,
     "end_time": "2025-09-10T11:36:00.430001",
     "exception": false,
     "start_time": "2025-09-10T11:36:00.313547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8233800,
     "sourceId": 13005933,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8233807,
     "sourceId": 13005942,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3546.643595,
   "end_time": "2025-09-10T11:36:02.373135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-10T10:36:55.729540",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
