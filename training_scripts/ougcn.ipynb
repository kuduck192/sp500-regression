{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c0efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def manual_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # if you are suing GPU\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "\ttotal_size = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "\treturn total_size / 1e6\n",
    "\n",
    "manual_seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10a513",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffcd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, load_edge\n",
    "\n",
    "train_folds = load_data(True)\n",
    "test_fold = load_data(False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49da85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SimpleStockDataset(Dataset):\n",
    "    def __init__(self, data, ws=128):\n",
    "        self.data = data\n",
    "        self.ws = ws\n",
    "        self.samples = []\n",
    "        \n",
    "        self.n_tickers, self.n_days, self.n_features = self.data.shape\n",
    "        \n",
    "        for start in range(self.n_days - self.ws + 1):\n",
    "            self.samples.append(start)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        start = self.samples[idx]\n",
    "        x = torch.tensor(self.data[:, start:start + self.ws], dtype=torch.float32)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3951fd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f3b1c",
   "metadata": {},
   "source": [
    "### TemporalGraphRefiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd467b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Literal\n",
    "\n",
    "\n",
    "class MyTemporalEncoderLayerBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_layers: int = 1, dropout: float = 0.0, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=(dropout if n_layers > 1 else 0.0),\n",
    "            bidirectional=True)\n",
    "\n",
    "        self.proj = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor):\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class GraphChebMix(nn.Module):\n",
    "    def __init__(self, Pdeg: int, d_latent: int, safety: float = 0.99, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.Pdeg = Pdeg\n",
    "        self.coeffs = nn.Parameter(torch.randn(Pdeg + 1) * 0.05)\n",
    "        self.safety = safety\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, L: torch.Tensor):\n",
    "        \"\"\"\n",
    "        X: (N, H, d_latent); per-time graph mixing.\n",
    "        \"\"\"\n",
    "        Y = self.apply_cheb_seq(L, X, self.coeffs, safety=self.safety)\n",
    "        return self.dropout(Y)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_cheb_seq(L, X, coeffs, safety=0.99):\n",
    "        I_N = torch.eye(L.shape[0], device=L.device, dtype=L.dtype)\n",
    "        S = I_N - L\n",
    "\n",
    "        s = coeffs.abs().sum().clamp_min(1e-12)\n",
    "        scale = min(1.0, float(safety)) / float(s)\n",
    "        c = coeffs * scale\n",
    "\n",
    "        T0 = X\n",
    "        if c.numel() == 1:\n",
    "            return c[0] * T0\n",
    "        T1 = torch.einsum('ij,jhd->ihd', S, X)\n",
    "        Y  = c[0] * T0 + c[1] * T1\n",
    "        for j in range(2, c.numel()):\n",
    "            T2 = 2 * torch.einsum('ij,jhd->ihd', S, T1) - T0\n",
    "            Y  = Y + c[j] * T2\n",
    "            T0, T1 = T1, T2\n",
    "        return Y\n",
    "      \n",
    "\n",
    "class TemporalGraphLayer(nn.Module):\n",
    "    def __init__(self, d_latent: int = 128,\n",
    "                 Pdeg: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.temporal_encoder = MyTemporalEncoderLayerBiLSTM(d_latent, d_latent)\n",
    "        self.graph_encoder = GraphChebMix(Pdeg=Pdeg, d_latent=d_latent, dropout=dropout)\n",
    "        self.ln_temporal = nn.LayerNorm(d_latent)\n",
    "        self.ln_graph = nn.LayerNorm(d_latent)\n",
    "        self.fuse = nn.Sequential(nn.Linear(2*d_latent, d_latent))\n",
    "        self.norm_out = nn.LayerNorm(d_latent)\n",
    "        \n",
    "\n",
    "    def forward(self, x, L):\n",
    "        \"\"\"\n",
    "        x:   (N, H, d_latent)\n",
    "        node_features: (N, d_node)\n",
    "        L: from your OUGCN\n",
    "        \"\"\"\n",
    "        nn.TransformerEncoderLayer\n",
    "        x_res = x\n",
    "        # temporal encoder\n",
    "        ht = self.ln_temporal(self.temporal_encoder(x)) # (N,H,d_latent)\n",
    "\n",
    "        # graph encoder\n",
    "        hg = self.ln_graph(self.graph_encoder(ht, L)) # (N,H,d_latent)\n",
    "\n",
    "        # fuse\n",
    "        h = self.fuse(torch.cat([ht, hg], dim=-1))                    # (N,H,d_latent)\n",
    "\n",
    "        out = self.norm_out(x_res + h)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "\n",
    "class TemporalGraphRefiner(nn.Module):\n",
    "    def __init__(self, n_feats: int, d_node: int, d_latent: int = 128,\n",
    "                 num_layers: int = 2, \n",
    "                 Pdeg: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.num_layers = num_layers\n",
    "        self.fc_in = nn.Linear(n_feats + d_node, d_latent)\n",
    "        self.temporal_graph_block = nn.ModuleList([\n",
    "            TemporalGraphLayer(self.d_latent, Pdeg, dropout)\n",
    "            for _ in range(self.num_layers)\n",
    "        ])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_latent, d_latent), nn.GELU(),\n",
    "            nn.Linear(d_latent, n_feats)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, node_features, L):\n",
    "        \"\"\"\n",
    "        x:   (N, H, F)\n",
    "        node_features: (N, d_node)\n",
    "        L: from your OUGCN\n",
    "        \"\"\"\n",
    "        N, H, F = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        node_broadcast = node_features.unsqueeze(1).expand(N, H, node_features.size(-1))\n",
    "        x = self.fc_in(torch.cat([x, node_broadcast], dim=-1))  # (N,H,d_latent)\n",
    "\n",
    "        for _, block in enumerate(self.temporal_graph_block):\n",
    "            x = block(x, L)\n",
    "        \n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da33d3b",
   "metadata": {},
   "source": [
    "### RNNBackbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Literal\n",
    "\n",
    "MyRNNArchitectureType = Literal['lstm']\n",
    "\n",
    "class MyLSTMBackbone(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_layers: int, dropout: float, **kwargs):\n",
    "        super().__init__()\n",
    "        self.d_in = input_size\n",
    "        self.d_latent = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.cells = nn.ModuleList([\n",
    "            nn.LSTMCell(self.d_in if i == 0 else self.d_latent, self.d_latent)\n",
    "            for i in range(self.n_layers)\n",
    "        ])\n",
    "\n",
    "    def init_states(self, X_0: torch.Tensor, H_0: Optional[torch.Tensor] = None) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        X_0: (N, d_in), H_0: (N, d_latent)\n",
    "        \"\"\"\n",
    "        device = X_0.device\n",
    "        dtype = X_0.dtype\n",
    "        N = X_0.shape[0]\n",
    "\n",
    "        h_list = [torch.zeros(N, self.d_latent, device=device, dtype=dtype) for _ in range(self.n_layers)]\n",
    "        c_list = [torch.zeros(N, self.d_latent, device=device, dtype=dtype) for _ in range(self.n_layers)]\n",
    "\n",
    "        if H_0 is not None:\n",
    "            if H_0.shape != (N, self.d_latent):\n",
    "                raise ValueError(f\"H_0 must be (N, {self.d_latent}), got {tuple(H_0.shape)}\")\n",
    "            h_list[-1] = H_0.to(device=device, dtype=dtype)\n",
    "\n",
    "        return h_list, c_list\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,  # (N, d_in)\n",
    "        hx: Optional[Tuple[List[torch.Tensor], List[torch.Tensor]]] = None\n",
    "    ) -> Tuple[torch.Tensor, Tuple[List[torch.Tensor], List[torch.Tensor]]]:\n",
    "        if hx is None:\n",
    "            hx = self.init_states(input)\n",
    "        h_list, c_list = hx\n",
    "\n",
    "        new_h, new_c = [], []\n",
    "        inp = input\n",
    "        for l, cell in enumerate(self.cells):\n",
    "            h_t, c_t = cell(inp, (h_list[l], c_list[l]))\n",
    "            if self.training and self.dropout > 0:\n",
    "                h_t = F.dropout(h_t, p=self.dropout, training=True)\n",
    "            new_h.append(h_t)\n",
    "            new_c.append(c_t)\n",
    "            inp = h_t\n",
    "\n",
    "        h_top = new_h[-1]\n",
    "        return h_top, (new_h, new_c)\n",
    "\n",
    "\n",
    "class MyRNNCell(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_layers: int = 1, dropout: float = 0.0, **kwargs):\n",
    "        super().__init__()\n",
    "        arch_type = kwargs.get('arch_type', 'lstm')\n",
    "        backbone_kwargs = kwargs.get('backbone_kwargs', {})\n",
    "        assert arch_type in ['lstm'], f'Arch not supported: {arch_type}'\n",
    "\n",
    "        self.rnn = MyLSTMBackbone(input_size, hidden_size, n_layers, dropout, **backbone_kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def make(cls, **kwargs) -> 'MyRNNCell':\n",
    "        \"\"\"\n",
    "        Create Customized RNN Cell compatible with OUGCN.\n",
    "        \"\"\"\n",
    "        default_arch_type: MyRNNArchitectureType = 'lstm'\n",
    "        defaults = {\n",
    "            'n_layers': 1,\n",
    "            'dropout': 0.1,\n",
    "            'arch_type': default_arch_type,\n",
    "        }\n",
    "        return MyRNNCell(**(defaults | kwargs))\n",
    "\n",
    "    def init_states(self, X_0: torch.Tensor, H_0: Optional[torch.Tensor] = None):\n",
    "        return self.rnn.init_states(X_0, H_0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        hx: Optional[Tuple[List[torch.Tensor], List[torch.Tensor]]] = None\n",
    "    ):\n",
    "        return self.rnn(input, hx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be37d6",
   "metadata": {},
   "source": [
    "### OUGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edb5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# Graph utilities\n",
    "# ------------------------------\n",
    "\n",
    "def pearson_corr_matrix(series: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute Pearson correlation across time for N series.\n",
    "    Args:\n",
    "        series: (N, T) time-series (already aligned), not all-constant.\n",
    "    Returns:\n",
    "        corr: (N, N) in [-1,1]\n",
    "    \"\"\"\n",
    "    N, T = series.shape\n",
    "    x = series - series.mean(dim=1, keepdim=True)\n",
    "    std = x.std(dim=1, unbiased=False, keepdim=True) + 1e-8\n",
    "    x = x / std\n",
    "    corr = (x @ x.t()) / T\n",
    "    corr = corr.clamp(-1.0, 1.0)\n",
    "    return corr\n",
    "\n",
    "\n",
    "def build_adjacency_from_corr(corr: torch.Tensor,\n",
    "                              keep_negative: bool = False,\n",
    "                              knn: Optional[int] = None,\n",
    "                              threshold: Optional[float] = None) -> torch.Tensor:\n",
    "    \"\"\"Turn correlation into nonnegative adjacency.\n",
    "    - If keep_negative=False: use relu to zero-out negative correlations.\n",
    "    - Optional: keep only top-k neighbors per node (excluding self) or apply threshold.\n",
    "    Returns A with zero diagonal.\n",
    "    \"\"\"\n",
    "    N = corr.shape[0]\n",
    "    if not keep_negative:\n",
    "        A = corr.relu()\n",
    "    else:\n",
    "        # shift to nonnegative range [0, 2] then rescale to [0,1]\n",
    "        A = (corr + 1.0) / 2.0\n",
    "        A = A.clamp(0.0, 1.0)\n",
    "    eye = torch.eye(N, device=A.device, dtype=torch.bool)\n",
    "    A = A.masked_fill(eye, 0.0)\n",
    "\n",
    "    if threshold is not None:\n",
    "        A = torch.where(A >= threshold, A, torch.zeros_like(A))\n",
    "\n",
    "    if knn is not None and knn > 0 and knn < N:\n",
    "        # retain top-k per row (excluding diagonal already 0)\n",
    "        topk_vals, topk_idx = torch.topk(A, k=knn, dim=1)\n",
    "        mask = torch.zeros_like(A, dtype=torch.bool)\n",
    "        mask.scatter_(1, topk_idx, True)\n",
    "        A = torch.where(mask, A, torch.zeros_like(A))\n",
    "        # symmetrize by max\n",
    "        A = torch.max(A, A.t())\n",
    "\n",
    "    # final symmetry\n",
    "    A = 0.5 * (A + A.t())\n",
    "    A = A.masked_fill(eye, 0.0)\n",
    "    return A\n",
    "\n",
    "def normalized_adjacency(A):\n",
    "    \"\"\"Compute Atilde = Dtilde^{-1/2}(A+I)Dtilde^{-1/2}.\"\"\"\n",
    "    I = torch.eye(A.size(0), device=A.device, dtype=A.dtype)\n",
    "    Ahat = A + I\n",
    "    d = Ahat.sum(1) + 1e-8\n",
    "    dinv = d.pow(-0.5)\n",
    "    return dinv[:,None] * Ahat * dinv[None,:]\n",
    "\n",
    "def normalized_laplacian(A):\n",
    "    \"\"\"Compute L = I - D^{-1/2} A D^{-1/2}.\"\"\"\n",
    "    d = A.sum(dim=1) + 1e-8\n",
    "    dinv = d.pow(-0.5)\n",
    "    S = dinv[:,None] * A * dinv[None,:]\n",
    "    I = torch.eye(A.size(0), device=A.device, dtype=A.dtype)\n",
    "    return I - S\n",
    "\n",
    "def power_iteration_lmax_sym(M: torch.Tensor, n_iter: int = 25) -> float:\n",
    "    \"\"\"Estimate largest eigenvalue (spectral radius) of symmetric PSD matrix M.\"\"\"\n",
    "    N = M.shape[0]\n",
    "    v = torch.randn(N, device=M.device, dtype=M.dtype)\n",
    "    v = v / (v.norm() + 1e-8)\n",
    "    for _ in range(n_iter):\n",
    "        v = M @ v\n",
    "        n = v.norm() + 1e-8\n",
    "        v = v / n\n",
    "    # Rayleigh quotient\n",
    "    lmax = float((v @ (M @ v)).item())\n",
    "    return max(lmax, 1e-12)\n",
    "  \n",
    "def spec_norm_2(A: torch.Tensor, n_iter: int = 25) -> torch.Tensor:\n",
    "    \"\"\"||A||_2 via power method on A^T A. Returns a scalar Tensor (has grad wrt A).\"\"\"\n",
    "    AtA = A.T @ A\n",
    "    v = torch.randn(AtA.shape[0], device=A.device, dtype=A.dtype)\n",
    "    v = v / (v.norm() + 1e-8)\n",
    "    for _ in range(n_iter):\n",
    "        v = AtA @ v\n",
    "        v = v / (v.norm() + 1e-8)\n",
    "    # sqrt(v^T (A^T A) v) = ||A v||, but this Rayleigh ~ lambda_max; take sqrt.\n",
    "    lam_max = v @ (AtA @ v)\n",
    "    return lam_max.clamp_min(1e-12).sqrt()  # Tensor\n",
    "\n",
    "def compute_poly(L, coeffs):\n",
    "    I_N = torch.eye(L.shape[0], device=L.device, dtype=L.dtype)\n",
    "    return apply_poly_to_emb(L, I_N, coeffs)\n",
    "\n",
    "def compute_cheb(L, coeffs, safety=0.99):\n",
    "    I_N = torch.eye(L.shape[0], device=L.device, dtype=L.dtype)\n",
    "    K = apply_cheb_to_emb(L, I_N, coeffs, safety)\n",
    "    \n",
    "    # lam_max = spec_norm_2(K)\n",
    "    # scale = min(1.0, safety / lam_max)\n",
    "    # return K * scale\n",
    "    \n",
    "    return K\n",
    "\n",
    "def apply_poly_to_emb(L, V, coeffs) -> torch.Tensor:\n",
    "    \"\"\"Compute K * V = sum_{i=0}^P coeffs_i * L^i * V.\n",
    "    \"\"\"\n",
    "    out = coeffs[0] * V\n",
    "    if coeffs.numel() == 1:\n",
    "        return out\n",
    "    LV = V\n",
    "    for i in range(1, coeffs.numel()):\n",
    "        LV = L @ LV          # O(N^2 d)\n",
    "        out = out + coeffs[i] * LV\n",
    "    return out\n",
    "\n",
    "def apply_cheb_to_emb(L, V, coeffs, safety=0.99):\n",
    "    \"\"\"\n",
    "    Tính y = sum_j c_j T_j(S) V\n",
    "    S = I - L (phổ trong [-1,1]); V: (N,d) hoặc (N,F)\n",
    "    \"\"\"\n",
    "    I_N = torch.eye(L.shape[0], device=L.device, dtype=L.dtype)\n",
    "    S = I_N - L\n",
    "\n",
    "    c = clamp_l1(coeffs, safety)\n",
    "    \n",
    "    if c.numel() == 1:\n",
    "        return c[0] * V\n",
    "    T0 = V\n",
    "    T1 = S @ V              # T1 = T_1(S)V\n",
    "    y  = c[0] * T0 + c[1] * T1\n",
    "    for j in range(2, c.numel()):\n",
    "        T2 = 2 * (S @ T1) - T0\n",
    "        y = y + c[j] * T2\n",
    "        T0, T1 = T1, T2\n",
    "    return y\n",
    "\n",
    "def clamp_l1(coeffs, safety=0.99):\n",
    "    s = coeffs.abs().sum().clamp_min(1e-12)\n",
    "    scale = torch.minimum(torch.tensor(1.0, device=coeffs.device, dtype=coeffs.dtype), safety / s)\n",
    "    return coeffs * scale\n",
    "\n",
    "# ------------------------------\n",
    "# Model definition\n",
    "# ------------------------------\n",
    "\n",
    "import math\n",
    "\n",
    "class MyGCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None, bias=True, dropout=0):\n",
    "        super(MyGCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_feats, out_feats))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_feats))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def graph_convolve(self, x, adj):\n",
    "        support = x @ self.weight\n",
    "        output = adj @ support\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.graph_convolve(x, adj)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        if self.training and self.dropout > 0:\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "class GatedCell(nn.Module):\n",
    "    def __init__(self, d_latent):\n",
    "        super().__init__()\n",
    "        self.z_gate = nn.Linear(2*d_latent, d_latent)\n",
    "        nn.init.constant_(self.z_gate.bias, -1.0)\n",
    "        self.proj_A = nn.Sequential(\n",
    "            nn.LayerNorm(d_latent),\n",
    "            nn.Linear(d_latent, d_latent),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.proj_B = nn.Sequential(\n",
    "            nn.LayerNorm(d_latent),\n",
    "            nn.Linear(d_latent, d_latent),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        z = torch.sigmoid(self.z_gate(torch.cat([self.proj_A(A), self.proj_B(B)], dim=-1)))\n",
    "        \n",
    "        A = (1 - z) * A + z * B\n",
    "        return A\n",
    "\n",
    "class OUGCN_with_Refiner(nn.Module):\n",
    "    def __init__(self, n_nodes: int, n_feats: int, args, node_emb=None):\n",
    "        super().__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.rank_adj = args.rank_adj\n",
    "        self.top_k_adj = args.top_k_adj\n",
    "        self.n_feats = n_feats\n",
    "        self.args = args\n",
    "        d_latent = args.d_latent\n",
    "        d_node = args.d_node\n",
    "        in_dropout = args.in_dropout\n",
    "        \n",
    "        rnn_kwargs:dict = getattr(args, 'rnn_kwargs', {})\n",
    "        \n",
    "        rnn_arch_type = rnn_kwargs.setdefault('rnn_arch_type', 'lstm')\n",
    "        rnn_n_layers = rnn_kwargs.setdefault('rnn_n_layers', 1)\n",
    "        rnn_hidden_dim = rnn_kwargs.setdefault('rnn_hidden_dim', 128)\n",
    "        rnn_dropout = rnn_kwargs.setdefault('rnn_dropout', 0.0)\n",
    "        rnn_backbone_kwargs = rnn_kwargs.setdefault('rnn_backbone_kwargs', {})\n",
    "        \n",
    "\n",
    "        if node_emb is None:\n",
    "            self.static_node_features = nn.Parameter(torch.randn(n_nodes, d_node) * 0.1)\n",
    "        else:\n",
    "            self.static_node_features = nn.Parameter(node_emb, requires_grad=False)\n",
    "            d_node = self.static_node_features.shape[-1]\n",
    "            \n",
    "        \n",
    "        self.fc_in = nn.Linear(n_feats + d_node, d_latent)\n",
    "        self.gcn_in = MyGCN(d_latent, d_latent, F.relu, dropout=in_dropout)\n",
    "        self.rnn_mean = MyRNNCell.make(\n",
    "            input_size=n_feats, hidden_size=rnn_hidden_dim,\n",
    "            n_layers=rnn_n_layers, dropout=rnn_dropout,\n",
    "            arch_type=rnn_arch_type,\n",
    "            backbone_kwargs=rnn_backbone_kwargs)\n",
    "        self.gcn_mean = MyGCN(rnn_hidden_dim, d_latent, F.relu, dropout=in_dropout)\n",
    "        self.fc_mean = nn.Linear(rnn_hidden_dim, d_latent)\n",
    "        \n",
    "        self.readout = nn.Sequential(\n",
    "            nn.Linear(d_latent, d_latent), nn.GELU(),\n",
    "            nn.Linear(d_latent, n_feats), nn.Tanh(),\n",
    "        )\n",
    "        self.res_scale = nn.Parameter(torch.ones(n_feats))\n",
    "        \n",
    "        self.kappa_H = nn.Parameter(torch.randn(args.Pdeg + 1) * 0.1)\n",
    "        self.kappa_M = nn.Parameter(torch.randn(args.Pdeg + 1) * 0.1)\n",
    "        \n",
    "        self.H_mix_module = GatedCell(d_latent)\n",
    "        self.M_mix_module = GatedCell(d_latent)\n",
    "        \n",
    "        self.fc_corr_features = nn.Sequential(\n",
    "            nn.Linear(d_node, d_latent), nn.ReLU(),\n",
    "            nn.Linear(d_latent, self.rank_adj)\n",
    "        )\n",
    "        # self.fc_node_features = nn.Sequential(\n",
    "        #     nn.Linear(d_node, d_latent), nn.ReLU(),\n",
    "        #     nn.Linear(d_latent, d_latent),\n",
    "        # )\n",
    "        \n",
    "        self.refiner = TemporalGraphRefiner(n_feats, d_node, d_latent,\n",
    "                                            **args.refiner_kwargs)\n",
    "        \n",
    "        self.corr_features = None\n",
    "        self.node_features = None\n",
    "        \n",
    "    def build_graph(self, X: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Build A (adj), Atilde (norm adj for GCN), and L (normalized Laplacian) from data X.\n",
    "        Right now we build a data-independent static learnable adj matrix.\n",
    "        X: (N, T, F)\n",
    "        Returns: (A, Atilde, L) all in device/dtype of X.\n",
    "        \"\"\"\n",
    "        # n_nodes, n_steps, n_feats = X.shape\n",
    "        if self.corr_features is None:\n",
    "            self.corr_features = self.fc_corr_features(self.static_node_features)\n",
    "        self.corr_features = F.normalize(self.corr_features, dim=-1)\n",
    "        A = self.corr_features @ self.corr_features.T\n",
    "        # A.fill_diagonal_(0.0)\n",
    "        A = build_adjacency_from_corr(A, keep_negative=False, knn=self.top_k_adj)\n",
    "        Atilde = normalized_adjacency(A)\n",
    "        L = normalized_laplacian(A)\n",
    "        return A, Atilde, L\n",
    "      \n",
    "\n",
    "    def _compute_graph_ops(self, X: torch.Tensor):\n",
    "        \"\"\"Helper: build Atilde, L, K, identity.\"\"\"\n",
    "        device = self.args.device\n",
    "        X = X.to(next(self.parameters()).device)\n",
    "        _, Atilde, L = self.build_graph(X)\n",
    "        Atilde = Atilde.to(device)\n",
    "        L = L.to(device)\n",
    "        \n",
    "        return Atilde, L\n",
    "    \n",
    "    def _step(self, X_t, H_t, H_filter, M_filter, gcn_filter, rnn_mean_latent=None):\n",
    "        Z_t_hist, rnn_mean_latent = self.rnn_mean.forward(X_t, rnn_mean_latent)\n",
    "        \n",
    "        M_t = self.fc_mean(Z_t_hist) + self.gcn_mean(Z_t_hist, gcn_filter) # mean embedding\n",
    "        \n",
    "        H_cand = self.H_mix_module(H_t, H_filter @ H_t)\n",
    "        M_cand = self.M_mix_module(M_t, M_filter @ M_t)\n",
    "        H_next = H_cand + M_cand\n",
    "        r_t = self.readout(H_next) * self.res_scale  # (N, F)\n",
    "        \n",
    "        return r_t, H_next, rnn_mean_latent\n",
    "\n",
    "    \n",
    "    \n",
    "    def forecast(self, X: torch.Tensor,\n",
    "                H_0: Optional[torch.Tensor] = None,\n",
    "                horizon: int = 0) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        y_pred, *_ = self.forward(X, H_0, horizon)\n",
    "        return y_pred\n",
    "    \n",
    "    def forward(self, X: torch.Tensor,\n",
    "                H_0: Optional[torch.Tensor] = None,\n",
    "                horizon: int = 0) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Run deterministic inference.\n",
    "        Args:\n",
    "            X: (N, T, F) input features at each t\n",
    "            H_0: (N, d) optional initial latent state (default zeros)\n",
    "            Atilde, L: if precomputed; otherwise build from X\n",
    "        Returns:\n",
    "            y_pred: (N, T-1) predicted next-day log-return for each node\n",
    "            H_all: (N, T, d) latent states (including H_0 as first)\n",
    "        \"\"\"\n",
    "        device = self.args.device\n",
    "        X = X.to(next(self.parameters()).device)\n",
    "        n_nodes, n_steps, n_feats = X.shape\n",
    "        d_latent = self.args.d_latent\n",
    "        \n",
    "        self.corr_features = self.fc_corr_features(self.static_node_features)\n",
    "        # self.node_features = self.fc_node_features(self.static_node_features)\n",
    "        \n",
    "\n",
    "        Atilde, L = self._compute_graph_ops(X)\n",
    "        I_N = torch.eye(L.shape[0], device=L.device, dtype=L.dtype)\n",
    "        \n",
    "        \n",
    "        self.L = L\n",
    "\n",
    "        X_0 = X[:, 0, :] # (N, F)\n",
    "        if H_0 is None:\n",
    "            x_in = self.fc_in(torch.cat([X_0, self.static_node_features], dim=-1)) # (N, F + d_node)\n",
    "            H_t = self.gcn_in(x_in, Atilde)\n",
    "        else:\n",
    "            H_t = H_0.to(device)\n",
    "        \n",
    "        # H_t = H_t + self.node_features\n",
    "\n",
    "        H_all = torch.zeros(n_nodes, n_steps + max(horizon, 0), d_latent, device=device, dtype=X.dtype)\n",
    "        r_all = torch.zeros(n_nodes, n_steps - 1 + max(horizon, 0), n_feats, device=device, dtype=X.dtype)\n",
    "        y_all = torch.zeros(n_nodes, n_steps - 1 + max(horizon, 0), n_feats, device=device, dtype=X.dtype)\n",
    "\n",
    "        H_all[:, 0] = H_t\n",
    "        \n",
    "        H_filter = compute_cheb(L, self.kappa_H)\n",
    "        M_filter = I_N - Atilde\n",
    "        gcn_filter = compute_cheb(L, self.kappa_M)\n",
    "        \n",
    "        rnn_mean_latent = self.rnn_mean.init_states(X_0, H_t)\n",
    "        \n",
    "        for t in range(n_steps - 1):\n",
    "            X_t = X[:, t, :] # (N, D)\n",
    "            r_t, H_next, rnn_mean_latent = self._step(X_t, H_t, H_filter, M_filter, gcn_filter, rnn_mean_latent)\n",
    "\n",
    "            H_all[:, t + 1] = H_next\n",
    "            r_all[:, t] = r_t\n",
    "            y_all[:, t] = X_t + r_t\n",
    "            H_t = H_next\n",
    "            \n",
    "        if horizon > 0:\n",
    "            X_t = X[:, -1, :]\n",
    "            for s in range(horizon):\n",
    "                r_t, H_next, rnn_mean_latent = self._step(X_t, H_t, H_filter, M_filter, gcn_filter, rnn_mean_latent)\n",
    "\n",
    "                H_all[:, n_steps + s] = H_next\n",
    "                r_all[:, n_steps - 1 + s] = r_t\n",
    "                H_t = H_next\n",
    "                \n",
    "                y_all[:, n_steps - 1 + s] = X_t + r_t\n",
    "                X_t = X_t + r_t\n",
    "        \n",
    "        r_refine = self.refiner.forward(y_all, self.static_node_features, L)\n",
    "        y_refine = y_all + r_refine\n",
    "        \n",
    "        return y_refine, r_refine, y_all, r_all, H_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward_loss(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "        H_0: Optional[torch.Tensor] = None,\n",
    "        horizon: int = 0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Tính loss dự báo one-step + rollout horizon (autoregressive) trên chuỗi đầu vào.\n",
    "\n",
    "        Args:\n",
    "            X: (N, T, F) chuỗi gốc (chứa full ground-truth đến T-1)\n",
    "            H_0: (N, d) latent init (tuỳ chọn)\n",
    "            horizon: số bước rollout ngoài quan sát cuối cùng\n",
    "                    (nếu >0, ta cắt input để tránh nhìn thấy tương lai)\n",
    "            reduction: 'mean' | 'sum' | 'none' cho F.mse_loss\n",
    "\n",
    "        Returns:\n",
    "            loss: scalar tensor\n",
    "            y_pred: (N, T-1, F) dự báo X_{t+1} cho toàn bộ t=0..T-2\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        X = X.to(device)\n",
    "        N, T, Fdim = X.shape\n",
    "\n",
    "        if horizon < 0:\n",
    "            raise ValueError(\"horizon must be >= 0\")\n",
    "        if horizon >= T:\n",
    "            raise ValueError(f\"horizon={horizon} must be < sequence length T={T}\")\n",
    "\n",
    "        # Cắt input nếu rollout > 0 để giữ đúng số target (T-1)\n",
    "        X_in = X[:, : T - horizon, :] if horizon > 0 else X\n",
    "\n",
    "        # forward() trả (N, (T-horizon)-1 + horizon, F) = (N, T-1, F)\n",
    "        y_refine, _, y_ar, _, _ = self.forward(X_in, H_0=H_0, horizon=horizon)\n",
    "\n",
    "        # Ground truth luôn là X_{1:T}\n",
    "        target = X[:, 1:, :]  # (N, T-1, F)\n",
    "        \n",
    "        err_t = (y_ar - target).abs().mean(dim=-1).mean(dim=0)\n",
    "        \n",
    "        decay = 0.9\n",
    "        coef_pre = 1.0\n",
    "        coef_roll = 1.0\n",
    "        \n",
    "        len_pre = T - horizon - 1\n",
    "        loss_pre = torch.tensor(0.0, device=device, dtype=err_t.dtype)\n",
    "        loss_roll = torch.tensor(0.0, device=device, dtype=err_t.dtype)\n",
    "\n",
    "        if len_pre > 0:\n",
    "            idx = torch.arange(len_pre - 1, -1, -1, device=device, dtype=err_t.dtype)\n",
    "            w = decay ** idx\n",
    "            loss_pre = (w * err_t[:len_pre]).sum() / (w.sum() + 1e-12)\n",
    "\n",
    "        if horizon > 0:\n",
    "            # MSE đều cho đoạn rollout (chiều dài = horizon)\n",
    "            loss_roll = err_t[len_pre:].mean()\n",
    "        \n",
    "        loss_refine = (y_refine - target).abs().mean()\n",
    "\n",
    "        loss = loss_refine + coef_pre * loss_pre + coef_roll * loss_roll\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4f0de",
   "metadata": {},
   "source": [
    "# Eval & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8ff2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def eval_ensemble(args, model, training_data_np, testing_data_np, device='cuda', seq_lens=[64, 96, 128], verbose=False):\n",
    "\n",
    "    used_features = [0, 1, 2, 3, 4, 5]\n",
    "    training_data_np = np.log1p(training_data_np[:, :, used_features])\n",
    "    testing_data_np = np.log1p(testing_data_np[:, :, used_features])\n",
    "    \n",
    "    labels = torch.tensor(testing_data_np).float().to(device)\n",
    "    n_nodes, horizon, n_feats = labels.shape\n",
    "    y_preds = np.zeros((len(seq_lens), n_nodes, horizon, n_feats-1)) # Bỏ Vol\n",
    "    model.eval().to(device)\n",
    "    for i, seq_len in enumerate(seq_lens):\n",
    "        batch = torch.tensor(training_data_np[:, -seq_len:]).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            y_all = model.forecast(batch, horizon=horizon)\n",
    "        y_preds[i] = y_all[:, -horizon:, :n_feats-1].detach().cpu().numpy() # OHLC + Adj Close\n",
    "    y_gt = testing_data_np[:, :, :n_feats-1].reshape(n_nodes, -1) # OHLC + Adj Close\n",
    "    y_pred = y_preds.mean(axis=0).reshape(n_nodes, -1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Max var:\", np.var(np.expm1(y_preds), axis=0).max())\n",
    "        print(\"Mean var:\", np.var(np.expm1(y_preds), axis=0).mean())\n",
    "    return {\n",
    "        'rmse': root_mean_squared_error(y_gt, y_pred), \n",
    "        'raw_rmse': root_mean_squared_error(np.expm1(y_gt), np.expm1(y_pred)), \n",
    "        'mae': mean_absolute_error(y_gt, y_pred), \n",
    "        'raw_mae': mean_absolute_error(np.expm1(y_gt), np.expm1(y_pred)), \n",
    "        'r2': r2_score(y_gt.ravel(), y_pred.ravel()),\n",
    "        'raw_r2': r2_score(np.expm1(y_gt).ravel(), np.expm1(y_pred).ravel()), \n",
    "    }\n",
    "\n",
    "def eval(args, model, training_data_np, testing_data_np, device='cuda'):\n",
    "    return eval_ensemble(args, model, training_data_np, testing_data_np, device, [args.seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafc31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        if self.avg == 0:\n",
    "            self.avg = val\n",
    "            return\n",
    "        self.avg = 0.95 * self.avg + 0.05 * val\n",
    "\n",
    "import copy\n",
    "def train(args, train_loader, model, optimizer, scheduler, training_data_np, testing_data_np):\n",
    "    # if args.amp:\n",
    "    #     from apex import amp\n",
    "    global best_loss, best_model\n",
    "    test_losses = []\n",
    "    end = time.time()\n",
    "\n",
    "    best_model = copy.deepcopy(model)\n",
    "    step = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        stats01 = AverageMeter()\n",
    "        stats02 = AverageMeter()\n",
    "        p_bar = tqdm(train_loader)\n",
    "        for batch_idx, samples in enumerate(p_bar):\n",
    "            step += 1\n",
    "            model.train().to(args.device)\n",
    "          \n",
    "            samples = samples[0].float().to(args.device)\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            loss = model.forward_loss(samples, horizon=args.horizon)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            max_norm = 5.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm).item()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            losses.update(loss.item())\n",
    "            stats01.update(0.0)\n",
    "            # stats01.update(power_iteration_lmax_sym(poly_laplacian(model.L, F.softplus(model.kappa))))\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            # mask_probs.update(mask.mean().item())\n",
    "            p_bar.set_description(\n",
    "                \"Ep: {epoch}/{epochs:3}. LR: {lr:.3e}. \"\n",
    "                \"Loss: {loss:.4f}. Stats01: {stats01:.4f}\".format(\n",
    "                epoch=epoch + 1,\n",
    "                epochs=args.epochs,\n",
    "                lr=scheduler.get_last_lr()[0],\n",
    "                data=data_time.avg,\n",
    "                bt=batch_time.avg,\n",
    "                loss=losses.avg,\n",
    "                stats01=stats01.avg,\n",
    "            ))\n",
    "            p_bar.update()\n",
    "            \n",
    "            if (step + 1) % args.eval_steps == 0:\n",
    "                test_model = model\n",
    "\n",
    "                test_metrics = eval_ensemble(args, test_model, training_data_np, testing_data_np, args.device, [args.seq_len])\n",
    "                print(test_metrics)\n",
    "                test_loss = test_metrics['mae']\n",
    "\n",
    "                is_best = test_loss < best_loss\n",
    "                if test_loss < best_loss:\n",
    "                    best_loss = test_loss\n",
    "                    best_model = copy.deepcopy(test_model)\n",
    "\n",
    "\n",
    "                test_losses.append(test_loss)\n",
    "                print('Best loss: {:.3f}'.format(best_loss))\n",
    "                print('Mean loss: {:.3f}\\n'.format(\n",
    "                    np.mean(test_losses[-20:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4bc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_cosine_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps,\n",
    "                                    num_training_steps,\n",
    "                                    num_cycles=7./16.,\n",
    "                                    last_epoch=-1):\n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        no_progress = float(current_step - num_warmup_steps) / \\\n",
    "            float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
    "\n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ce9a9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25b9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def manual_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # if you are suing GPU\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "\ttotal_size = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "\treturn total_size / 1e6\n",
    "\n",
    "class Config:\n",
    "    # Training\n",
    "    epochs = 5\n",
    "    eval_steps = 200\n",
    "    lr = 1e-4\n",
    "    wd = 1e-3\n",
    "    warmup = 0\n",
    "    \n",
    "    n_nodes = 428\n",
    "    n_feats = 6\n",
    "    \n",
    "    # Prediction\n",
    "    seq_len = 96\n",
    "    horizon = 32\n",
    "    \n",
    "    # OUGCN\n",
    "    d_node: int = 32\n",
    "    in_dropout: float = 0.0\n",
    "    d_latent: int = 128\n",
    "    Pdeg: int = 2                  # polynomial degree of Laplacian in K\n",
    "    safety: float = 0.99           # stability safety factor\n",
    "    device: str = \"cuda\"\n",
    "    top_k_adj: int = 32\n",
    "    rank_adj: int = 32\n",
    "    \n",
    "    # RNN kwargs\n",
    "    rnn_kwargs = {\n",
    "        'rnn_arch_type': 'lstm',\n",
    "        'rnn_n_layers': 1,\n",
    "        'rnn_dropout': 0.0,\n",
    "        'rnn_hidden_dim': 128,\n",
    "        'rnn_backbone_kwargs': { },\n",
    "    }\n",
    "    \n",
    "    # Refiner kwargs\n",
    "    refiner_kwargs = {\n",
    "        'num_layers': 1,\n",
    "        'Pdeg': 2,\n",
    "        'dropout': 0.1,\n",
    "    }\n",
    "    seed = 42\n",
    "\n",
    "args = Config()\n",
    "manual_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adbbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb_path=\"../input/static_node_emb.npy\"\n",
    "node_emb_matrix = torch.tensor(np.load(node_emb_path), dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train_fold(fold_idx):\n",
    "    global training_data_np, testing_data_np\n",
    "    used_features = [0, 1, 2, 3, 4, 5]\n",
    "    training_data_np = np.log1p(train_folds[fold_idx][0][:, :, used_features])\n",
    "    testing_data_np = np.log1p(train_folds[fold_idx][1][:, :, used_features])\n",
    "    train_loader = DataLoader(SimpleStockDataset(training_data_np, args.seq_len + args.horizon), batch_size=1, shuffle=True)\n",
    "    \n",
    "    manual_seed(args.seed + fold_idx)\n",
    "        \n",
    "    model = OUGCN_with_Refiner(args.n_nodes, args.n_feats, args, node_emb=node_emb_matrix)\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "    total_steps = args.epochs * len(train_loader)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=args.warmup,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "    \n",
    "    print(f'Model size: {get_model_size(model) * 1e3:.2f}K')\n",
    "    \n",
    "    # Sanity check\n",
    "    print(eval_ensemble(args, model, training_data_np, testing_data_np, args.device, [2, 4]))\n",
    "    \n",
    "    global best_loss, best_model\n",
    "    best_loss = 9999\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    train(args, train_loader, model, optimizer, scheduler, training_data_np, testing_data_np)\n",
    "    \n",
    "    return best_model, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b49c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 630.33K\n",
      "{'rmse': 0.380309881486751, 'raw_rmse': 579.2165059396674, 'mae': 0.3428282398365135, 'raw_mae': 129.83877709089793, 'r2': 0.775560176849138, 'raw_r2': -6.986756850649582}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.999e-05. Loss: 0.3201. Stats01: 0.0000:   6%|▌         | 219/3529 [02:14<36:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.10707334198143661, 'raw_rmse': 43.942521752764236, 'mae': 0.09157104603100927, 'raw_mae': 19.235482651270896, 'r2': 0.984412341705579, 'raw_r2': 0.9903683831264545}\n",
      "Best loss: 0.092\n",
      "Mean loss: 0.092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.995e-05. Loss: 0.3168. Stats01: 0.0000:  12%|█▏        | 427/3529 [04:37<48:12,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.09551845733961495, 'raw_rmse': 42.956224472408515, 'mae': 0.07985732003660735, 'raw_mae': 17.670086399113746, 'r2': 0.9878442000839696, 'raw_r2': 0.9911661504642908}\n",
      "Best loss: 0.080\n",
      "Mean loss: 0.086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.989e-05. Loss: 0.3016. Stats01: 0.0000:  18%|█▊        | 634/3529 [07:44<39:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08099990546139797, 'raw_rmse': 33.2661863122052, 'mae': 0.06252817886883644, 'raw_mae': 13.569174981319957, 'r2': 0.9906760188461735, 'raw_r2': 0.9948468407728508}\n",
      "Best loss: 0.063\n",
      "Mean loss: 0.078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.981e-05. Loss: 0.2841. Stats01: 0.0000:  24%|██▍       | 839/3529 [10:51<41:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08456490343212174, 'raw_rmse': 49.92634166349647, 'mae': 0.0671057458812477, 'raw_mae': 16.530334689194426, 'r2': 0.9910245504742486, 'raw_r2': 0.9873858297467437}\n",
      "Best loss: 0.063\n",
      "Mean loss: 0.075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.970e-05. Loss: 0.2577. Stats01: 0.0000:  30%|██▉       | 1044/3529 [13:02<24:16,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08524057165902361, 'raw_rmse': 40.57053167094432, 'mae': 0.06767289194614172, 'raw_mae': 15.411100935116227, 'r2': 0.989941747099362, 'raw_r2': 0.9926780250971825}\n",
      "Best loss: 0.063\n",
      "Mean loss: 0.074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.956e-05. Loss: 0.2647. Stats01: 0.0000:  35%|███▌      | 1248/3529 [15:03<22:57,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.09094366000676074, 'raw_rmse': 39.57723923564668, 'mae': 0.07542725985521002, 'raw_mae': 16.270665450531553, 'r2': 0.9891697921924792, 'raw_r2': 0.9928097515168822}\n",
      "Best loss: 0.063\n",
      "Mean loss: 0.074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.941e-05. Loss: 0.2565. Stats01: 0.0000:  41%|████      | 1452/3529 [17:09<20:53,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08055922669108534, 'raw_rmse': 31.248443355673334, 'mae': 0.06365124810490805, 'raw_mae': 13.61684144595778, 'r2': 0.9920060462139344, 'raw_r2': 0.9958988468824975}\n",
      "Best loss: 0.063\n",
      "Mean loss: 0.073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.923e-05. Loss: 0.2548. Stats01: 0.0000:  47%|████▋     | 1656/3529 [19:11<15:57,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.07570289287901687, 'raw_rmse': 35.35045638815908, 'mae': 0.05669932030978189, 'raw_mae': 13.69355228792736, 'r2': 0.9928167537044831, 'raw_r2': 0.9943104147224644}\n",
      "Best loss: 0.057\n",
      "Mean loss: 0.071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.902e-05. Loss: 0.2525. Stats01: 0.0000:  53%|█████▎    | 1859/3529 [20:35<10:37,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08005921902901356, 'raw_rmse': 38.05587132453037, 'mae': 0.06181343452692814, 'raw_mae': 15.1410943189822, 'r2': 0.9917530681535538, 'raw_r2': 0.9932329875317361}\n",
      "Best loss: 0.057\n",
      "Mean loss: 0.070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.879e-05. Loss: 0.2528. Stats01: 0.0000:  58%|█████▊    | 2062/3529 [21:51<09:05,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.08168296434498619, 'raw_rmse': 34.43049290726285, 'mae': 0.06475566434186744, 'raw_mae': 13.763093221730387, 'r2': 0.9914631747490419, 'raw_r2': 0.994659063644358}\n",
      "Best loss: 0.057\n",
      "Mean loss: 0.069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.854e-05. Loss: 0.2430. Stats01: 0.0000:  64%|██████▍   | 2265/3529 [23:05<08:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06819730201955225, 'raw_rmse': 30.387762329695946, 'mae': 0.048148852271544765, 'raw_mae': 11.55273355966306, 'r2': 0.994307755490576, 'raw_r2': 0.9960795840563312}\n",
      "Best loss: 0.048\n",
      "Mean loss: 0.067\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.826e-05. Loss: 0.2346. Stats01: 0.0000:  70%|██████▉   | 2468/3529 [24:20<06:10,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0683189156552521, 'raw_rmse': 31.00928358635717, 'mae': 0.04874954553041807, 'raw_mae': 11.571269449595885, 'r2': 0.9943701281333612, 'raw_r2': 0.9959865640167348}\n",
      "Best loss: 0.048\n",
      "Mean loss: 0.066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.796e-05. Loss: 0.2288. Stats01: 0.0000:  76%|███████▌  | 2671/3529 [25:36<06:16,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06908171595487672, 'raw_rmse': 27.435232711696454, 'mae': 0.050051448487294446, 'raw_mae': 10.909601313553745, 'r2': 0.9940658842138047, 'raw_r2': 0.9968265579039534}\n",
      "Best loss: 0.048\n",
      "Mean loss: 0.064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.763e-05. Loss: 0.2411. Stats01: 0.0000:  81%|████████▏ | 2874/3529 [26:51<03:59,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06268322629462868, 'raw_rmse': 24.145620001471997, 'mae': 0.04225775915488704, 'raw_mae': 9.46333882119759, 'r2': 0.9952085456703283, 'raw_r2': 0.9976153060461708}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.728e-05. Loss: 0.2299. Stats01: 0.0000:  87%|████████▋ | 3076/3529 [28:04<02:50,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.07091956739459968, 'raw_rmse': 29.18379479451576, 'mae': 0.05254021158094157, 'raw_mae': 11.458154786826121, 'r2': 0.9939375241794307, 'raw_r2': 0.996371666140348}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.062\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.691e-05. Loss: 0.2334. Stats01: 0.0000:  93%|█████████▎| 3279/3529 [29:17<01:31,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06784772338760514, 'raw_rmse': 26.09471316135411, 'mae': 0.04930131923530237, 'raw_mae': 10.445645915927532, 'r2': 0.9943650895509516, 'raw_r2': 0.9970944598233477}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.652e-05. Loss: 0.2285. Stats01: 0.0000:  99%|█████████▊| 3481/3529 [31:06<00:28,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06364333362041939, 'raw_rmse': 27.43092496480894, 'mae': 0.043276120206755725, 'raw_mae': 10.148611469073428, 'r2': 0.9950938315385451, 'raw_r2': 0.9966859709662272}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.060\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 1/  5. LR: 9.625e-05. Loss: 0.2310. Stats01: 0.0000: 100%|██████████| 3529/3529 [32:25<00:00,  1.81it/s]\n",
      "Ep: 2/  5. LR: 9.610e-05. Loss: 0.2374. Stats01: 0.0000:   2%|▏         | 82/3529 [00:42<30:08,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06351557614675085, 'raw_rmse': 25.51855483452781, 'mae': 0.043586907225662684, 'raw_mae': 9.81726235108789, 'r2': 0.9951565594668645, 'raw_r2': 0.9973188702778734}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.565e-05. Loss: 0.2233. Stats01: 0.0000:   8%|▊         | 293/3529 [02:42<32:06,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06545612705098239, 'raw_rmse': 26.251370202768065, 'mae': 0.04604500320880332, 'raw_mae': 10.231830863306996, 'r2': 0.9948325589409062, 'raw_r2': 0.997154896809997}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.519e-05. Loss: 0.2240. Stats01: 0.0000:  14%|█▍        | 501/3529 [04:42<27:13,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06743763589508735, 'raw_rmse': 25.65401883728691, 'mae': 0.048642875389139736, 'raw_mae': 10.597848659380626, 'r2': 0.994543211036594, 'raw_r2': 0.9972953975464813}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.470e-05. Loss: 0.2134. Stats01: 0.0000:  20%|██        | 707/3529 [06:42<25:49,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06602776332434596, 'raw_rmse': 27.114482463550534, 'mae': 0.04677288527096173, 'raw_mae': 10.420747412046172, 'r2': 0.9947054536393211, 'raw_r2': 0.9968930309794943}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.419e-05. Loss: 0.2230. Stats01: 0.0000:  26%|██▌       | 912/3529 [08:43<25:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06426247003618266, 'raw_rmse': 27.19684210282654, 'mae': 0.044715821065258544, 'raw_mae': 10.197797333811685, 'r2': 0.9950491864614814, 'raw_r2': 0.9969338556093239}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.365e-05. Loss: 0.2162. Stats01: 0.0000:  32%|███▏      | 1116/3529 [10:42<23:45,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06487649855911072, 'raw_rmse': 26.188328906448415, 'mae': 0.04560495540510056, 'raw_mae': 9.958073891978941, 'r2': 0.9949406448372057, 'raw_r2': 0.9971416717376018}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.309e-05. Loss: 0.2159. Stats01: 0.0000:  37%|███▋      | 1320/3529 [12:41<22:13,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06399415069236114, 'raw_rmse': 23.967643448271172, 'mae': 0.044058512309272053, 'raw_mae': 9.581902786237716, 'r2': 0.995017250448533, 'raw_r2': 0.9975979038217526}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.052\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.251e-05. Loss: 0.2155. Stats01: 0.0000:  43%|████▎     | 1524/3529 [14:41<19:20,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06583959623158427, 'raw_rmse': 28.8906459455353, 'mae': 0.04613842236005105, 'raw_mae': 10.780193665970174, 'r2': 0.9947857893486957, 'raw_r2': 0.9964814581182099}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.191e-05. Loss: 0.2288. Stats01: 0.0000:  49%|████▉     | 1728/3529 [16:40<17:32,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06492081083059678, 'raw_rmse': 26.270400738194038, 'mae': 0.0454053153927422, 'raw_mae': 10.067063134110484, 'r2': 0.9948818577346853, 'raw_r2': 0.9970846640711205}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.050\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.129e-05. Loss: 0.2218. Stats01: 0.0000:  55%|█████▍    | 1931/3529 [18:39<15:48,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06475804810409241, 'raw_rmse': 24.579120220927194, 'mae': 0.04482318221337671, 'raw_mae': 9.80748296999421, 'r2': 0.9950105658829087, 'raw_r2': 0.9975478528631317}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 9.064e-05. Loss: 0.2088. Stats01: 0.0000:  60%|██████    | 2134/3529 [20:38<13:33,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06303512891765517, 'raw_rmse': 25.90440281342561, 'mae': 0.042439666902457235, 'raw_mae': 9.951043944956886, 'r2': 0.9951974541966951, 'raw_r2': 0.9971879881390819}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.997e-05. Loss: 0.2123. Stats01: 0.0000:  66%|██████▌   | 2337/3529 [22:38<11:52,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06596912442239178, 'raw_rmse': 26.855125183410323, 'mae': 0.04654430103974664, 'raw_mae': 10.288904679830958, 'r2': 0.9947198379610859, 'raw_r2': 0.9969387594955343}\n",
      "Best loss: 0.042\n",
      "Mean loss: 0.047\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.928e-05. Loss: 0.2197. Stats01: 0.0000:  72%|███████▏  | 2540/3529 [24:38<09:54,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06159936973078773, 'raw_rmse': 24.29618365919352, 'mae': 0.04094627187449216, 'raw_mae': 9.300656594919626, 'r2': 0.99547104180766, 'raw_r2': 0.9976131523748498}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.857e-05. Loss: 0.2107. Stats01: 0.0000:  78%|███████▊  | 2743/3529 [26:37<07:45,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0610933691564088, 'raw_rmse': 24.867260167487412, 'mae': 0.040517179007530324, 'raw_mae': 9.198081969450175, 'r2': 0.9955033770544683, 'raw_r2': 0.9974742005360432}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.783e-05. Loss: 0.2074. Stats01: 0.0000:  83%|████████▎ | 2946/3529 [28:06<03:20,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06327029240475768, 'raw_rmse': 25.39072603377994, 'mae': 0.04317254933733441, 'raw_mae': 9.774033591002434, 'r2': 0.9951783948715424, 'raw_r2': 0.9973290390331897}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.708e-05. Loss: 0.2145. Stats01: 0.0000:  89%|████████▉ | 3148/3529 [29:16<02:13,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06764990527704269, 'raw_rmse': 27.588464913205225, 'mae': 0.04883791381816727, 'raw_mae': 10.649109857055878, 'r2': 0.9944805357128272, 'raw_r2': 0.9968148028836672}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.630e-05. Loss: 0.2093. Stats01: 0.0000:  95%|█████████▍| 3351/3529 [30:25<01:01,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06393132470603416, 'raw_rmse': 25.46686671778081, 'mae': 0.04414216695314485, 'raw_mae': 9.791373102603462, 'r2': 0.9950960217921707, 'raw_r2': 0.9973255447210184}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.550e-05. Loss: 0.2112. Stats01: 0.0000: : 3553it [31:34,  2.88it/s]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06577031048072976, 'raw_rmse': 26.82776050008454, 'mae': 0.04618431879310074, 'raw_mae': 10.158534320603628, 'r2': 0.9948307227853025, 'raw_r2': 0.9970940048466644}\n",
      "Best loss: 0.041\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 2/  5. LR: 8.526e-05. Loss: 0.2069. Stats01: 0.0000: 100%|██████████| 3529/3529 [31:54<00:00,  1.84it/s]\n",
      "Ep: 3/  5. LR: 8.469e-05. Loss: 0.2122. Stats01: 0.0000:   4%|▍         | 158/3529 [00:48<17:24,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.060209911893805736, 'raw_rmse': 23.416768061650977, 'mae': 0.03941983768828995, 'raw_mae': 8.986242174692988, 'r2': 0.9956352507468043, 'raw_r2': 0.9977420660686344}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 8.385e-05. Loss: 0.2119. Stats01: 0.0000:  10%|█         | 367/3529 [01:57<17:57,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06530506363155264, 'raw_rmse': 27.6385944918017, 'mae': 0.045661969803434996, 'raw_mae': 10.302005148868018, 'r2': 0.9949008157396768, 'raw_r2': 0.9968331405620127}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 8.299e-05. Loss: 0.2118. Stats01: 0.0000:  16%|█▋        | 574/3529 [03:06<16:47,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06195460733698544, 'raw_rmse': 23.276746783299767, 'mae': 0.04160712559272451, 'raw_mae': 9.209858358210255, 'r2': 0.9954215437325235, 'raw_r2': 0.9978168441372262}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 8.211e-05. Loss: 0.2042. Stats01: 0.0000:  22%|██▏       | 779/3529 [04:15<15:38,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061564666258535246, 'raw_rmse': 23.69308567805731, 'mae': 0.04117529194954563, 'raw_mae': 9.156745447648584, 'r2': 0.9954623605665833, 'raw_r2': 0.9977399189615482}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 8.121e-05. Loss: 0.2129. Stats01: 0.0000:  28%|██▊       | 984/3529 [05:24<14:23,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06432280895141727, 'raw_rmse': 23.914600383211507, 'mae': 0.04448748463477696, 'raw_mae': 9.635776563740803, 'r2': 0.9950878734945877, 'raw_r2': 0.997686885512267}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 8.029e-05. Loss: 0.2125. Stats01: 0.0000:  34%|███▎      | 1189/3529 [06:33<13:30,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06077637873847408, 'raw_rmse': 23.443043673927292, 'mae': 0.040211361437779314, 'raw_mae': 8.979509771466901, 'r2': 0.9955651740759521, 'raw_r2': 0.9977459913600141}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.935e-05. Loss: 0.2059. Stats01: 0.0000:  39%|███▉      | 1393/3529 [07:43<12:21,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06330665298822534, 'raw_rmse': 23.96242651984666, 'mae': 0.04345713313306927, 'raw_mae': 9.475557771101556, 'r2': 0.9951796735299892, 'raw_r2': 0.9976216371149771}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.839e-05. Loss: 0.2041. Stats01: 0.0000:  45%|████▌     | 1597/3529 [08:52<08:47,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06570275779603182, 'raw_rmse': 27.141556235566444, 'mae': 0.04613949061985703, 'raw_mae': 10.47966454424214, 'r2': 0.9948253086281797, 'raw_r2': 0.9969798913979496}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.742e-05. Loss: 0.2116. Stats01: 0.0000:  51%|█████     | 1800/3529 [10:01<10:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06328044201433426, 'raw_rmse': 25.34038184307984, 'mae': 0.04291543079224529, 'raw_mae': 9.62474859897042, 'r2': 0.9952206581274956, 'raw_r2': 0.9973842448966957}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.642e-05. Loss: 0.2003. Stats01: 0.0000:  57%|█████▋    | 2003/3529 [11:11<08:39,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06191947831996331, 'raw_rmse': 23.87479148497513, 'mae': 0.041637430279805696, 'raw_mae': 9.221012503251787, 'r2': 0.9953987704300455, 'raw_r2': 0.9976750002368603}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.541e-05. Loss: 0.1950. Stats01: 0.0000:  63%|██████▎   | 2206/3529 [12:20<07:43,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06024001752731339, 'raw_rmse': 22.990830147895736, 'mae': 0.03928743540381634, 'raw_mae': 8.923371479463178, 'r2': 0.9956370510431481, 'raw_r2': 0.9978623629752083}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.438e-05. Loss: 0.2042. Stats01: 0.0000:  68%|██████▊   | 2409/3529 [13:30<06:20,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.062264280524391716, 'raw_rmse': 24.61275730372577, 'mae': 0.04222389377221862, 'raw_mae': 9.312661642165388, 'r2': 0.9953169909070372, 'raw_r2': 0.9974745399220621}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.332e-05. Loss: 0.2034. Stats01: 0.0000:  74%|███████▍  | 2612/3529 [14:39<05:19,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.062337850349389747, 'raw_rmse': 24.74353753094578, 'mae': 0.0422596566419202, 'raw_mae': 9.477557841062275, 'r2': 0.9953468514792946, 'raw_r2': 0.9975297163038659}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.226e-05. Loss: 0.2010. Stats01: 0.0000:  80%|███████▉  | 2815/3529 [15:48<04:03,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06427859165128784, 'raw_rmse': 25.623378186960114, 'mae': 0.04482093523921743, 'raw_mae': 9.797936753880547, 'r2': 0.9950615441950733, 'raw_r2': 0.9973191948075248}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.117e-05. Loss: 0.2155. Stats01: 0.0000:  86%|████████▌ | 3018/3529 [16:57<02:58,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06434237584990046, 'raw_rmse': 24.62344658478556, 'mae': 0.04458541265317739, 'raw_mae': 9.890306118733818, 'r2': 0.9950843600760177, 'raw_r2': 0.9975431429226592}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 7.007e-05. Loss: 0.2026. Stats01: 0.0000:  91%|█████████ | 3220/3529 [18:07<01:49,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061423706837213626, 'raw_rmse': 24.79389522510861, 'mae': 0.0406972083411852, 'raw_mae': 9.502426003240098, 'r2': 0.9954509898437165, 'raw_r2': 0.9974774378035864}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 6.895e-05. Loss: 0.2165. Stats01: 0.0000:  97%|█████████▋| 3423/3529 [19:16<00:35,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06353563214264299, 'raw_rmse': 23.582198994934075, 'mae': 0.043721703409691316, 'raw_mae': 9.437254761435776, 'r2': 0.9951849142269544, 'raw_r2': 0.9977421015984111}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 3/  5. LR: 6.788e-05. Loss: 0.1968. Stats01: 0.0000: 100%|██████████| 3529/3529 [20:20<00:00,  2.89it/s]\n",
      "Ep: 4/  5. LR: 6.781e-05. Loss: 0.2021. Stats01: 0.0000:   0%|          | 17/3529 [00:04<14:04,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06174225411135385, 'raw_rmse': 23.795768182065547, 'mae': 0.04130975244665015, 'raw_mae': 9.211913350706347, 'r2': 0.9954528860105516, 'raw_r2': 0.9977076937441544}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.666e-05. Loss: 0.1982. Stats01: 0.0000:   7%|▋         | 233/3529 [01:13<14:27,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06167405180387255, 'raw_rmse': 22.86951449238331, 'mae': 0.04122486308016873, 'raw_mae': 9.043414834306496, 'r2': 0.9954640428838852, 'raw_r2': 0.9979042606647301}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.549e-05. Loss: 0.2053. Stats01: 0.0000:  12%|█▏        | 441/3529 [02:22<16:26,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06301525601043761, 'raw_rmse': 24.066854616610225, 'mae': 0.043156231928602296, 'raw_mae': 9.414517132639595, 'r2': 0.9952589929399781, 'raw_r2': 0.9976385796757761}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.430e-05. Loss: 0.2022. Stats01: 0.0000:  18%|█▊        | 647/3529 [03:31<16:39,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06218584405940501, 'raw_rmse': 23.96386992386893, 'mae': 0.041917885358400624, 'raw_mae': 9.330978106412553, 'r2': 0.9953741350091856, 'raw_r2': 0.9976715220188406}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.310e-05. Loss: 0.1937. Stats01: 0.0000:  24%|██▍       | 852/3529 [04:40<15:07,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061909028589182374, 'raw_rmse': 23.513693499874794, 'mae': 0.04156618828020336, 'raw_mae': 9.190340559998289, 'r2': 0.9954318056499956, 'raw_r2': 0.9977744349556252}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.189e-05. Loss: 0.2007. Stats01: 0.0000:  30%|██▉       | 1057/3529 [05:49<13:54,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0607440668353967, 'raw_rmse': 23.926853203098226, 'mae': 0.03980319359030482, 'raw_mae': 9.237777112296827, 'r2': 0.9955614319822569, 'raw_r2': 0.9976840511010582}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 6.066e-05. Loss: 0.1973. Stats01: 0.0000:  36%|███▌      | 1261/3529 [06:57<13:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06067816145112281, 'raw_rmse': 23.448944844405855, 'mae': 0.04003026412576769, 'raw_mae': 8.974018560290862, 'r2': 0.9955844379479923, 'raw_r2': 0.9977739920150215}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.941e-05. Loss: 0.1932. Stats01: 0.0000:  42%|████▏     | 1465/3529 [08:06<11:45,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06065520081590775, 'raw_rmse': 23.126285955826706, 'mae': 0.03990728089207964, 'raw_mae': 8.966914725251803, 'r2': 0.9955991358741164, 'raw_r2': 0.997850379841403}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.815e-05. Loss: 0.2015. Stats01: 0.0000:  47%|████▋     | 1669/3529 [09:15<10:33,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06194382027937731, 'raw_rmse': 23.986096220640466, 'mae': 0.04174531906106316, 'raw_mae': 9.328836726493359, 'r2': 0.9954293573800651, 'raw_r2': 0.997685434273461}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.687e-05. Loss: 0.1975. Stats01: 0.0000:  53%|█████▎    | 1872/3529 [10:24<09:30,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061853949414176115, 'raw_rmse': 24.464516482823537, 'mae': 0.04143902747226208, 'raw_mae': 9.29875782098789, 'r2': 0.9954187696916322, 'raw_r2': 0.997547026382178}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.559e-05. Loss: 0.1948. Stats01: 0.0000:  59%|█████▉    | 2075/3529 [11:33<08:27,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06144031544942015, 'raw_rmse': 23.07139076762953, 'mae': 0.041094130309245545, 'raw_mae': 9.02435918404969, 'r2': 0.9954896396303208, 'raw_r2': 0.9978557146235221}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.428e-05. Loss: 0.1947. Stats01: 0.0000:  65%|██████▍   | 2279/3529 [12:42<05:42,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06046621850670241, 'raw_rmse': 22.687888623703415, 'mae': 0.03978377544596897, 'raw_mae': 8.866650865850621, 'r2': 0.9956223647170426, 'raw_r2': 0.9979155396313373}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.297e-05. Loss: 0.1945. Stats01: 0.0000:  70%|███████   | 2481/3529 [13:51<06:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061302763170063335, 'raw_rmse': 23.33794744196101, 'mae': 0.0410048216530292, 'raw_mae': 9.017925562325962, 'r2': 0.995497584102999, 'raw_r2': 0.9977955686479524}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.164e-05. Loss: 0.1929. Stats01: 0.0000:  76%|███████▌  | 2684/3529 [15:00<04:47,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.061429747605946605, 'raw_rmse': 22.931782275894285, 'mae': 0.04104594313585758, 'raw_mae': 9.020374794841779, 'r2': 0.9954790353913792, 'raw_r2': 0.9978761266693691}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 5.030e-05. Loss: 0.2007. Stats01: 0.0000:  82%|████████▏ | 2887/3529 [16:09<03:40,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06135315940789392, 'raw_rmse': 23.641654313812523, 'mae': 0.04088880872520133, 'raw_mae': 9.083495844122403, 'r2': 0.9954953203660458, 'raw_r2': 0.9977300760020202}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 4.895e-05. Loss: 0.1883. Stats01: 0.0000:  88%|████████▊ | 3090/3529 [17:19<02:24,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.060259447638782854, 'raw_rmse': 22.763921043482767, 'mae': 0.03952965456019184, 'raw_mae': 8.86468232947878, 'r2': 0.9956381715669421, 'raw_r2': 0.9979016367464661}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 4.759e-05. Loss: 0.2002. Stats01: 0.0000:  93%|█████████▎| 3292/3529 [18:28<01:21,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06314311001313282, 'raw_rmse': 25.062827251847143, 'mae': 0.04335894527191716, 'raw_mae': 9.463407561030062, 'r2': 0.9952640725933426, 'raw_r2': 0.997456503069185}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 4.621e-05. Loss: 0.1977. Stats01: 0.0000:  99%|█████████▉| 3495/3529 [19:36<00:11,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06174724094994275, 'raw_rmse': 22.742889232346705, 'mae': 0.04155098076310156, 'raw_mae': 9.088293210119652, 'r2': 0.9954853239509583, 'raw_r2': 0.997966416246402}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 4/  5. LR: 4.540e-05. Loss: 0.1910. Stats01: 0.0000: 100%|██████████| 3529/3529 [20:17<00:00,  2.90it/s]\n",
      "Ep: 5/  5. LR: 4.482e-05. Loss: 0.1882. Stats01: 0.0000:   3%|▎         | 96/3529 [00:28<18:07,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06183348028578926, 'raw_rmse': 23.582974871289725, 'mae': 0.041492978202569676, 'raw_mae': 9.169627661032658, 'r2': 0.995435352334347, 'raw_r2': 0.9977521707710955}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 4.342e-05. Loss: 0.2025. Stats01: 0.0000:   9%|▊         | 307/3529 [01:37<17:32,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0606165422296335, 'raw_rmse': 23.204757987616876, 'mae': 0.040058611147977596, 'raw_mae': 8.918229792331244, 'r2': 0.9955854736515287, 'raw_r2': 0.9978002114332915}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 4.202e-05. Loss: 0.1941. Stats01: 0.0000:  15%|█▍        | 514/3529 [02:46<17:11,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.060951960856928056, 'raw_rmse': 23.144469730801042, 'mae': 0.04044513789661137, 'raw_mae': 8.991662937247826, 'r2': 0.9955388490945836, 'raw_r2': 0.9978177869656073}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 4.060e-05. Loss: 0.1913. Stats01: 0.0000:  20%|██        | 720/3529 [03:54<16:09,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06116795138207682, 'raw_rmse': 23.71094133779235, 'mae': 0.0404544420550034, 'raw_mae': 9.153013806911458, 'r2': 0.9955349323175343, 'raw_r2': 0.9977352875968928}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.917e-05. Loss: 0.1912. Stats01: 0.0000:  26%|██▌       | 925/3529 [05:04<14:51,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06007816147003955, 'raw_rmse': 22.44387848038696, 'mae': 0.03942147681487161, 'raw_mae': 8.827656683241802, 'r2': 0.9956619050075604, 'raw_r2': 0.9979406528703525}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.773e-05. Loss: 0.1958. Stats01: 0.0000:  32%|███▏      | 1130/3529 [06:14<10:43,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06129286442530055, 'raw_rmse': 23.4850070233405, 'mae': 0.040759817801042805, 'raw_mae': 9.09230375385016, 'r2': 0.9955042079722414, 'raw_r2': 0.9977588214531106}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.628e-05. Loss: 0.1905. Stats01: 0.0000:  38%|███▊      | 1334/3529 [07:23<12:12,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06115971940761028, 'raw_rmse': 22.744299155611813, 'mae': 0.04067276955497418, 'raw_mae': 8.973430489028026, 'r2': 0.9955176241386868, 'raw_r2': 0.9979237876673531}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.483e-05. Loss: 0.1863. Stats01: 0.0000:  44%|████▎     | 1537/3529 [08:32<11:33,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.060551433122104446, 'raw_rmse': 22.833873520696557, 'mae': 0.039857363230296664, 'raw_mae': 8.879040451615387, 'r2': 0.9956025398357953, 'raw_r2': 0.9978959763755862}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.336e-05. Loss: 0.1862. Stats01: 0.0000:  49%|████▉     | 1741/3529 [09:42<10:16,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06080802158183705, 'raw_rmse': 22.450706437953894, 'mae': 0.04021759619074875, 'raw_mae': 8.857452490859071, 'r2': 0.9955701015218394, 'raw_r2': 0.9979743094521727}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.189e-05. Loss: 0.1936. Stats01: 0.0000:  55%|█████▌    | 1944/3529 [10:51<09:07,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06027920749340942, 'raw_rmse': 22.87945762993693, 'mae': 0.03953669251519566, 'raw_mae': 8.866923620147627, 'r2': 0.9956474349056189, 'raw_r2': 0.9978880602930779}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 3.041e-05. Loss: 0.1919. Stats01: 0.0000:  61%|██████    | 2148/3529 [12:00<06:47,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06146035855513302, 'raw_rmse': 22.94237534695467, 'mae': 0.04109017334935127, 'raw_mae': 9.056744302154108, 'r2': 0.9954771244819629, 'raw_r2': 0.9978717282767272}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.892e-05. Loss: 0.1885. Stats01: 0.0000:  67%|██████▋   | 2351/3529 [13:10<06:14,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06175272628498514, 'raw_rmse': 23.327660704786016, 'mae': 0.04160559949395584, 'raw_mae': 9.15561962238587, 'r2': 0.9954351792975865, 'raw_r2': 0.9978030419805194}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.743e-05. Loss: 0.1957. Stats01: 0.0000:  72%|███████▏  | 2553/3529 [14:20<05:38,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06214643942018843, 'raw_rmse': 24.313893200608987, 'mae': 0.042083929722621864, 'raw_mae': 9.272185882744884, 'r2': 0.9953987310262146, 'raw_r2': 0.9976075731740203}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.593e-05. Loss: 0.1867. Stats01: 0.0000:  78%|███████▊  | 2756/3529 [15:30<04:23,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0601087608885091, 'raw_rmse': 22.873094080152228, 'mae': 0.039353770948938924, 'raw_mae': 8.887618972206244, 'r2': 0.9956398200804802, 'raw_r2': 0.9978664593875438}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.442e-05. Loss: 0.1891. Stats01: 0.0000:  84%|████████▍ | 2959/3529 [16:39<03:19,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.0613876019694867, 'raw_rmse': 23.097690011249973, 'mae': 0.04109188874181451, 'raw_mae': 9.016372635961519, 'r2': 0.9954946141132758, 'raw_r2': 0.9978393546455055}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.290e-05. Loss: 0.1884. Stats01: 0.0000:  90%|████████▉ | 3162/3529 [17:49<01:37,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06054193440170199, 'raw_rmse': 22.715989195932607, 'mae': 0.039974858973833974, 'raw_mae': 8.849714885885303, 'r2': 0.9956066811691276, 'raw_r2': 0.9979078076187528}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 2.138e-05. Loss: 0.1901. Stats01: 0.0000:  95%|█████████▌| 3364/3529 [18:58<00:57,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.060956687276683796, 'raw_rmse': 22.946781955097716, 'mae': 0.040474125556018564, 'raw_mae': 8.93738502757644, 'r2': 0.995548036239072, 'raw_r2': 0.9978610648075709}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 1.986e-05. Loss: 0.1872. Stats01: 0.0000: : 3566it [20:07,  2.90it/s]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06089760425634423, 'raw_rmse': 23.046491518789182, 'mae': 0.04038734056244652, 'raw_mae': 8.94984586887213, 'r2': 0.9955575926450944, 'raw_r2': 0.9978499637623406}\n",
      "Best loss: 0.039\n",
      "Mean loss: 0.041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep: 5/  5. LR: 1.951e-05. Loss: 0.1865. Stats01: 0.0000: 100%|██████████| 3529/3529 [20:24<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "best_model, best_loss = train_fold(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8216be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.05892767556592564,\n",
       " 'raw_rmse': 29.64633468760002,\n",
       " 'mae': 0.042399002905476824,\n",
       " 'raw_mae': 10.570864551249285,\n",
       " 'r2': 0.996062632975289,\n",
       " 'raw_r2': 0.9968318397948741}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = test_fold[0], test_fold[1]\n",
    "eval_ensemble(args, best_model, data, labels, args.device, [args.seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f003158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.05891323298691096,\n",
       " 'raw_rmse': 29.813343638095866,\n",
       " 'mae': 0.04238265815226493,\n",
       " 'raw_mae': 10.580564301318097,\n",
       " 'r2': 0.9960644855150232,\n",
       " 'raw_r2': 0.9967942889802358}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = test_fold[0], test_fold[1]\n",
    "eval_ensemble(args, best_model, data, labels, args.device, [32, 64, 96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6104b828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.05892493875372378,\n",
       " 'raw_rmse': 29.666546527718307,\n",
       " 'mae': 0.04239628013934455,\n",
       " 'raw_mae': 10.571961484432132,\n",
       " 'r2': 0.9960629972134678,\n",
       " 'raw_r2': 0.9968272838327025}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = test_fold[0], test_fold[1]\n",
    "eval_ensemble(args, best_model, data, labels, args.device, [64, 96, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0812d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
